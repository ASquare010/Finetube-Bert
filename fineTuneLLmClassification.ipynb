{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers datasets trl peft bitsandbytes scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\awais\\Desktop\\finetubeLLm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "from datasets import load_dataset,Dataset,DatasetDict\n",
    "from peft import LoraConfig,get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch. cuda. is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Classes labels for the model to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    \"cited\": 0,\n",
    "    \"applied\": 1,\n",
    "    \"followed\": 2,\n",
    "    \"referred to\": 3,\n",
    "    \"related\": 4,\n",
    "    \"considered\": 5,\n",
    "    \"discussed\": 6,\n",
    "    \"distinguished\": 7,\n",
    "    \"affirmed\": 8,\n",
    "    \"approved\": 9\n",
    "}\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and rename accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "df = df.drop(columns=['case_id','case_text'])\n",
    "\n",
    "df = df.dropna(subset=['case_title', 'case_outcome'])\n",
    "\n",
    "df = df.rename(columns={'case_title': 'text', 'case_outcome': 'label'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the labels and remove null valise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                               text\n",
      "0          0  Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...\n",
      "1          0  Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...\n",
      "2          0  Colgate Palmolive Co v Cussons Pty Ltd (1993) ...\n",
      "3          0  Dais Studio Pty Ltd v Bullett Creative Pty Ltd...\n",
      "4          0  Dr Martens Australia Pty Ltd v Figgins Holding...\n",
      "...      ...                                                ...\n",
      "24980      0  Reches Pty Ltd v Tadiran Pty Ltd (1998) 85 FCR...\n",
      "24981      0  Sir Lindsay Parkinson &amp; Co Ltd v Triplan L...\n",
      "24982      0  Spiel v Commodity Brokers Australia Pty Ltd (I...\n",
      "24983      7  Tullock Ltd v Walker (Unreported, Supreme Cour...\n",
      "24984      7  Yandil Holdings Pty Ltd v Insurance Co of Nort...\n",
      "\n",
      "[24985 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awais\\AppData\\Local\\Temp\\ipykernel_16500\\3396769366.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['label'] = df['label'].replace(label_map)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to replace labels with IDs in DataFrame\n",
    "def replace_labels(df, label_map):\n",
    "    df['label'] = df['label'].replace(label_map)\n",
    "    return df\n",
    "\n",
    "# Replace labels with IDs in DataFrame\n",
    "df_train = replace_labels(df, label2id)\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "dataset = Dataset.from_pandas(df_cleaned)\n",
    "\n",
    "print(df_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 19988\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 4997\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "dataset = dataset.remove_columns(['__index_level_0__'])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and tokinizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id,\n",
    "                                             num_labels=id2label.__len__(), \n",
    "                                             id2label=id2label,\n",
    "                                             label2id=label2id,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_accutacy():\n",
    "    text_list = [\"Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Ltd (No 2) [2002] FCA 224 ; (2002) 190 ALR 121\",\n",
    "                \"TCN Channel Nine Pty Ltd v Australian Broadcasting Tribunal (1992) 28 ALD 829\",\n",
    "                \"Australian Securities and Investments Commission v Pegasus Leveraged Options Group Pty Ltd (2002) 41 ACSR 561\"\n",
    "                \"Waterford v Commonwealth [1987] HCA 25\",\n",
    "                \"Heinrich v Commonwealth Bank of Australia [2003] FCAFC 315\",\n",
    "                \"X v Australian Crime Commission [2004] FCA 1475\",\n",
    "                \"Commissioner for Australian Capital Territory Revenue v Alphaone Pty Ltd (1994) 49 FCR 576 \"\n",
    "                ]\n",
    "    print(\"----------------------------\")\n",
    "    for text in text_list:\n",
    "        # tokenize text\n",
    "        inputs = tokenizer.encode(text, return_tensors=\"pt\").to('cuda')\n",
    "        # compute logits\n",
    "        logits = model(inputs).logits\n",
    "        # convert logits to label\n",
    "        predictions = torch.argmax(logits)\n",
    "\n",
    "        print(text + \" - \" + id2label[predictions.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Ltd (No 2) [2002] FCA 224 ; (2002) 190 ALR 121 - cited\n",
      "TCN Channel Nine Pty Ltd v Australian Broadcasting Tribunal (1992) 28 ALD 829 - approved\n",
      "Australian Securities and Investments Commission v Pegasus Leveraged Options Group Pty Ltd (2002) 41 ACSR 561Waterford v Commonwealth [1987] HCA 25 - approved\n",
      "Heinrich v Commonwealth Bank of Australia [2003] FCAFC 315 - approved\n",
      "X v Australian Crime Commission [2004] FCA 1475 - approved\n",
      "Commissioner for Australian Capital Territory Revenue v Alphaone Pty Ltd (1994) 49 FCR 576  - approved\n"
     ]
    }
   ],
   "source": [
    "check_model_accutacy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add pad token if none exists\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "#     model.resize_token_embeddings(len(tokenizer))\n",
    "# def tokenize_function(examples):\n",
    "#     #tokenize and truncate text\n",
    "#     tokenizer.truncation_side = \"left\"\n",
    "#     tokenized_inputs = tokenizer(\n",
    "#         examples['text'],\n",
    "#         return_tensors=\"np\",\n",
    "#         truncation=True,\n",
    "#         max_length=512\n",
    "#     )\n",
    "\n",
    "#     return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], padding=\"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19988/19988 [00:03<00:00, 5425.96 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4997/4997 [00:00<00:00, 5753.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 19988\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 4997\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "print(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an evaluation function to pass into trainer later\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                        r=4,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.01,\n",
    "                        target_modules = ['q_lin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at WindowsPath('c:/Users/awais/Desktop/finetubeLLm/.venv/Lib/site-packages/bitsandbytes/libbitsandbytes_cuda124_nocublaslt.dll')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 635,146 || all params: 67,596,308 || trainable%: 0.9396\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\awais\\Desktop\\finetubeLLm\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"model/save\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    # max_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [03:02<00:00,  2.10it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5998820066452026, 'eval_accuracy': {'accuracy': 0.4916950170102061}, 'eval_runtime': 157.8437, 'eval_samples_per_second': 31.658, 'eval_steps_per_second': 7.919, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\awais\\Desktop\\finetubeLLm\\.venv\\Lib\\site-packages\\peft\\utils\\other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 48591195-fbd6-4bed-addc-5b4ee05317ab)') - silently ignoring the lookup for the file config.json in distilbert-base-uncased.\n",
      "  warnings.warn(\n",
      "c:\\Users\\awais\\Desktop\\finetubeLLm\\.venv\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in distilbert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [03:12<00:00,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 192.6054, 'train_samples_per_second': 2.077, 'train_steps_per_second': 0.26, 'train_loss': 1.7433152770996094, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=1.7433152770996094, metrics={'train_runtime': 192.6054, 'train_samples_per_second': 2.077, 'train_steps_per_second': 0.26, 'total_flos': 53774986444800.0, 'train_loss': 1.7433152770996094, 'epoch': 0.020008003201280513})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [02:37<00:00,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5998820066452026, 'eval_accuracy': {'accuracy': 0.4916950170102061}, 'eval_runtime': 157.5429, 'eval_samples_per_second': 31.718, 'eval_steps_per_second': 7.934, 'epoch': 0.020008003201280513}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Ltd (No 2) [2002] FCA 224 ; (2002) 190 ALR 121 - cited\n",
      "TCN Channel Nine Pty Ltd v Australian Broadcasting Tribunal (1992) 28 ALD 829 - cited\n",
      "Australian Securities and Investments Commission v Pegasus Leveraged Options Group Pty Ltd (2002) 41 ACSR 561Waterford v Commonwealth [1987] HCA 25 - cited\n",
      "Heinrich v Commonwealth Bank of Australia [2003] FCAFC 315 - cited\n",
      "X v Australian Crime Commission [2004] FCA 1475 - cited\n",
      "Commissioner for Australian Capital Territory Revenue v Alphaone Pty Ltd (1994) 49 FCR 576  - cited\n"
     ]
    }
   ],
   "source": [
    "check_model_accutacy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"model/save/fine-tuned-model\")\n",
    "# tokenizer.save_pretrained(\"model/save/fine-tuned-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
